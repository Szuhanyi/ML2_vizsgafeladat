{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV, DataFrames, Plots\n",
    "\n",
    "base_dir = \"./input/train/\"\n",
    "tr1_dir = \"defog/\"\n",
    "tr1_fr  = 100\n",
    "tr2_dir = \"tdcsfog/\"\n",
    "tr2_fr  = 128\n",
    "\n",
    "# simulating the dataLoader\n",
    "all_files = readdir(base_dir*tr1_dir)\n",
    "\n",
    "rr = rand(1:length(all_files))\n",
    "@show rr\n",
    "# reading in a specific file\n",
    "df1 = CSV.read(base_dir*tr1_dir*all_files[rr] , DataFrames.DataFrame)\n",
    "df1.Time ./= tr1_fr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = CSV.read(\"./input/events.csv\", DataFrames.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii = size(df1)[1]\n",
    "sii = rand(1:nii)\n",
    "aii = sii .+ (1:min(nii-sii,500*tr1_fr))\n",
    "\n",
    "p = Plots.plot(size=(1300,400)) # layout=(3,1),\n",
    "color = 2 .* df1.StartHesitation .+ df1.Turn\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccV[aii], color=color[aii], label=false,title=\"AccV\",titlefontsize=9,msw=0,ms=1)\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccML[aii],color=color[aii], label=false,title=\"AccML\",titlefontsize=9,msw=0,ms=1)\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccAP[aii],color=color[aii], label=false,title=\"AccAP\",titlefontsize=9,msw=0,ms=1)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(\"need_to_average.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming from Freq1 to Freq2\n",
    "\n",
    "This section is about the transformation of a signal at frequency $\\omega_1$ to a signal with frequency $\\omega_2$, where frequency means the times a signal is sampled __in a second__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transform(d1, fr1::Integer, fr2::Integer)\n",
    "    \n",
    "    nd1 = length(d1)\n",
    "    nd2 = Int(floor(nd1*fr2/fr1))\n",
    "    λ   = (0:(nd2-1))*fr1/fr2\n",
    "    ii1 = Int.(floor.(λ))\n",
    "    λ  -= ii1\n",
    "    d1  = vcat(deepcopy(d1), d1[end])\n",
    "\n",
    "    return (1 .- λ) .* d1[1 .+ ii1] + λ .* d1[2 .+ ii1]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# debug\n",
    "#t0 = collect(0:1.25:10)\n",
    "#t,λ = transform(t0,8,10)\n",
    "#@show t\n",
    "\n",
    "accV1 = df1.AccV[aii]\n",
    "time1 = df1.Time[aii]\n",
    "accV2 = transform(accV1, tr1_fr, tr2_fr)\n",
    "time2 = transform(time1, tr1_fr, tr2_fr)\n",
    "\n",
    "p = Plots.scatter(time1, accV1) # df1.AccV[aii])\n",
    "Plots.scatter!(p, time2, accV2 ,msw=0,ms=2) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot!(p,xlim=(1100,1101))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the second data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating the dataLoader\n",
    "all_f2 = readdir(base_dir*tr2_dir)\n",
    "\n",
    "rr2 = rand(1:length(all_f2))\n",
    "@show rr2\n",
    "# reading in a specific file\n",
    "df2 = CSV.read(base_dir*tr2_dir*all_f2[rr2] , DataFrames.DataFrame)\n",
    "df2.Time ./= tr2_fr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii = size(df2)[1]\n",
    "sii = rand(1:nii)\n",
    "aii = sii .+ (1:min(nii-sii,10*tr2_fr))\n",
    "\n",
    "p = Plots.plot(layout=(3,1),size=(800,400))\n",
    "color = 2 .* df2.StartHesitation .+ df2.Turn\n",
    "Plots.plot!(p[1], df2.Time[aii], df2.AccV[aii], color=color[aii], label=false,title=\"AccV\",titlefontsize=9)\n",
    "Plots.plot!(p[1], df1.Time[aii], df1.AccV[aii], label=false,title=\"AccV\",titlefontsize=9)\n",
    "\n",
    "Plots.plot!(p[2], df2.Time[aii], df2.AccML[aii],color=color[aii], label=false,title=\"AccML\",titlefontsize=9)\n",
    "Plots.plot!(p[2], df1.Time[aii], df1.AccML[aii], label=false,title=\"AccML\",titlefontsize=9)\n",
    "\n",
    "Plots.plot!(p[3], df2.Time[aii], df2.AccAP[aii],color=color[aii], label=false,title=\"AccAP\",titlefontsize=9)\n",
    "Plots.plot!(p[3], df1.Time[aii], df1.AccAP[aii], label=false,title=\"AccAP\",titlefontsize=9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your task is to:\n",
    "\n",
    "1. build a data loader that samples the __events__ (from the \"events.csv\" file), copies chunks using a number $D$ of _continuous_ samples. The output is assigned as a weights into which classes are present in the series of length $D$.\n",
    "\n",
    "1. Build a neural network that is capable to read in $D$ values and produce a $K$ outputs, where $K$ is the number of different classifications possible.\n",
    "\n",
    "1. Evaluate the system for different values of $D$ and different architectures.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 * D - bemenet\n",
    "atfeldolgozo reget(in,out) \n",
    "lstm(in,out), (in,64)\n",
    "maxpool(64,16), \n",
    "dense(16,3)\n",
    "softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we don't need a struct, \n",
    "# ehh \n",
    "struct myDataLoader\n",
    "    sampler\n",
    "    D\n",
    "    getNextBatch\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV, DataFrames, Plots\n",
    "events = CSV.read(\"./input/events.csv\", DataFrames.DataFrame)\n",
    "\n",
    "\n",
    "function transform(d1, fr1::Integer, fr2::Integer)\n",
    "    \n",
    "    nd1 = length(d1)\n",
    "    nd2 = Int(floor(nd1*fr2/fr1))\n",
    "    λ   = (0:(nd2-1))*fr1/fr2\n",
    "    ii1 = Int.(floor.(λ))\n",
    "    λ  -= ii1\n",
    "    d1  = vcat(deepcopy(d1), d1[end])\n",
    "\n",
    "    return (1 .- λ) .* d1[1 .+ ii1] + λ .* d1[2 .+ ii1]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loadFile(path)\n",
    "    CSV.read(path, DataFrames.DataFrame)\n",
    "end\n",
    "#load in rows in time interval [first,last]\n",
    "function loadRecording(file_name, first_index, last_index)\n",
    "    data = []\n",
    "    path_tdcs = \"./input/train/tdcsfog/\"\n",
    "    path_de = \"./input/train/defog/\"\n",
    "    path_notype = \"./input/train/notype/\"\n",
    "    frequency = 128\n",
    "    try \n",
    "        data = loadFile(path_tdcs * file_name*\".csv\")\n",
    "    catch\n",
    "        try\n",
    "            frequency = 100\n",
    "            data = loadFile(path_de * file_name*\".csv\")\n",
    "        catch \n",
    "            # it means we have notype\n",
    "            # do we want to load them in , or what ? because the structure is a bit different, there are no event type annotations.. \n",
    "            # data = loadFile(path_notype * file_name*\".csv\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    index_start = trunc(Int64,frequency *first_index ) + 2\n",
    "    index_end = min(trunc(Int64,frequency *last_index ) + 1,size(data)[1])\n",
    "\n",
    "\n",
    "    (Matrix(data[index_start:index_end,:]),frequency)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load D samples from events.csv \n",
    "function loadSamplesFromEvents(starting_from::Int32, num_d::Int32, event_df::DataFrames.DataFrame )\n",
    "    num_events = size(event_df)[1]\n",
    "    ending_with = min(starting_from+num_d-1,num_events) # to avoid \"index not found\" exception \n",
    "    # select events to be loaded \n",
    "    # we could also do also just load randomly , if that is desired \n",
    "    chosen_events = [event_df[row,:] for row in starting_from:ending_with]\n",
    "    train_data = []    \n",
    "    for event in chosen_events\n",
    "        series_event = loadRecording(event.Id,event.Init,event.Completion)\n",
    "        push!(train_data,series_event)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    train_data\n",
    "end\n",
    "raw_data = loadSamplesFromEvents(1,10,events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = [x==100 for (_,x) in raw_data]\n",
    "raw_data[low_freq]\n",
    "# I guess data should be transformed.. sometime for training ? anyway.. the first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transform_batch(batch) \n",
    "    # not sure how to do that .. we can , or should only transform the signals.. or we we extend also the labels ?? ehh \n",
    "    batch\n",
    "end\n",
    "\n",
    "function getNextBatch(data_loader)\n",
    "    from_index = data_loader.current_index\n",
    "    chunk_size = data_loader.d\n",
    "    \n",
    "    batch = loadSamplesFromEvents(from_index,chunk_size,data_loader.events_dataframe)\n",
    "    data_loader.current_index += chunk_size\n",
    "    #maybe there is no need for reset.. mark it as to be removed ? \n",
    "    # if (data_loder.current_index > size(data_loader.events_dataframe)[1])\n",
    "    #     data_loader.current_index = 1\n",
    "    # end \n",
    "    # transform data if neccessary I guess \n",
    "    batch = transform_batch(batch)\n",
    "\n",
    "    batch\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct data_loader \n",
    "    current_index::Int32\n",
    "    d::Int32\n",
    "    getNext\n",
    "    events_dataframe\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Any}:\n",
       " ([1103.0 -9.39529972114623 … 1.0 0.0; 1104.0 -9.16660317480122 … 1.0 0.0; … ; 1889.0 -8.5489501493737 … 1.0 0.0; 1890.0 -8.56789013914377 … 1.0 0.0], 128)\n",
       " ([1458.0 -8.94870175413821 … 1.0 0.0; 1459.0 -9.05473787136403 … 1.0 0.0; … ; 5270.0 -8.91070800593675 … 1.0 0.0; 5271.0 -8.86710149396174 … 1.0 0.0], 128)\n",
       " ([6998.0 -10.2779361750618 … 1.0 0.0; 6999.0 -9.99570845868899 … 1.0 0.0; … ; 7523.0 -9.61131702426238 … 1.0 0.0; 7524.0 -9.17878724878662 … 1.0 0.0], 128)\n",
       " ([3597.0 -8.69936143533898 … 1.0 0.0; 3598.0 -8.77127881535382 … 1.0 0.0; … ; 3876.0 -8.60192171420836 … 1.0 0.0; 3877.0 -8.6538965989354 … 1.0 0.0], 128)\n",
       " ([3881.0 -9.16232640273608 … 1.0 0.0; 3882.0 -9.13981486072401 … 1.0 0.0; … ; 4079.0 -10.0472318960615 … 1.0 0.0; 4080.0 -10.5986136370634 … 1.0 0.0], 128)\n",
       " ([2054.0 -9.58634938862899 … 1.0 0.0; 2055.0 -9.41231919415004 … 1.0 0.0; … ; 2206.0 -9.95826843635929 … 1.0 0.0; 2207.0 -10.0628253297948 … 1.0 0.0], 128)\n",
       " ([2510.0 -10.9445153324145 … 1.0 0.0; 2511.0 -10.4187890040757 … 1.0 0.0; … ; 2636.0 -8.52627925677611 … 1.0 0.0; 2637.0 -8.83465643790808 … 1.0 0.0], 128)\n",
       " ([2111.0 -9.76780225097328 … 1.0 0.0; 2112.0 -10.0753886255984 … 1.0 0.0; … ; 2253.0 -9.19211661412227 … 1.0 0.0; 2254.0 -9.19530136839325 … 1.0 0.0], 128)\n",
       " ([4461.0 -9.21214861516373 … 1.0 0.0; 4462.0 -9.26138122551309 … 1.0 0.0; … ; 4731.0 -9.25569298690608 … 1.0 0.0; 4732.0 -9.14387047902633 … 1.0 0.0], 128)\n",
       " ([4774.0 -9.07833241991207 … 1.0 0.0; 4775.0 -9.01729057263429 … 1.0 0.0; … ; 5099.0 -9.44682313439086 … 1.0 0.0; 5100.0 -9.43902510375752 … 1.0 0.0], 128)\n",
       " ⋮\n",
       " ([1585.0 -9.06676479708216 … 1.0 0.0; 1586.0 -9.1207475204517 … 1.0 0.0; … ; 2550.0 -9.49901432007474 … 1.0 0.0; 2551.0 -9.74766313308064 … 1.0 0.0], 128)\n",
       " ([2588.0 -9.52299184326241 … 1.0 0.0; 2589.0 -9.45683791706717 … 1.0 0.0; … ; 3533.0 -10.4650131872492 … 0.0 0.0; 3534.0 -10.3351612659598 … 0.0 0.0], 128)\n",
       " ([3484.0 -9.86435307083475 … 0.0 0.0; 3485.0 -9.4819163043425 … 0.0 0.0; … ; 3748.0 -10.0281121715639 … 0.0 0.0; 3749.0 -9.92251193047251 … 0.0 0.0], 128)\n",
       " ([5773.0 -8.69395934235105 … 1.0 0.0; 5774.0 -8.75414915202354 … 1.0 0.0; … ; 5935.0 -10.0647476006612 … 1.0 0.0; 5936.0 -10.1115203555606 … 1.0 0.0], 128)\n",
       " ([2021.0 -9.17515724630281 … 1.0 0.0; 2022.0 -8.8366995081689 … 1.0 0.0; … ; 2132.0 -11.0942791225959 … 1.0 0.0; 2133.0 -10.7271570971407 … 1.0 0.0], 128)\n",
       " ([1508.0 -11.7908583137876 … 1.0 0.0; 1509.0 -11.7195429406818 … 1.0 0.0; … ; 1918.0 -10.3128926202299 … 1.0 0.0; 1919.0 -10.4460737734189 … 1.0 0.0], 128)\n",
       " ([2028.0 -10.5020168810059 … 1.0 0.0; 2029.0 -10.5409605522691 … 1.0 0.0; … ; 2103.0 -10.2618674312084 … 1.0 0.0; 2104.0 -9.8228970123085 … 1.0 0.0], 128)\n",
       " ([2904.0 -9.45418292167427 … 1.0 0.0; 2905.0 -9.35043517199984 … 1.0 0.0; … ; 3024.0 -9.64316878393028 … 1.0 0.0; 3025.0 -9.77370710117817 … 1.0 0.0], 128)\n",
       " ([3641.0 -9.85279199730776 … 1.0 0.0; 3642.0 -10.1166214972799 … 1.0 0.0; … ; 3780.0 -9.24898757733859 … 1.0 0.0; 3781.0 -9.35343910635902 … 1.0 0.0], 128)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create train data \n",
    "\n",
    "dataLoader = data_loader(1,100,getNextBatch,events)\n",
    "dataLoader.getNext(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataLoader.getNext(dataLoader)\n",
    "\n",
    "sampler(D,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the model.. LSTM ?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recur(\n",
       "  LSTMCell(3 => 5),                     \u001b[90m# 190 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: 5 trainable arrays, \u001b[39m190 parameters,\n",
       "\u001b[90m          # plus 2 non-trainable, 10 parameters, summarysize \u001b[39m1.062 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = LSTM(3=>5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
