{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV, DataFrames, Plots\n",
    "\n",
    "base_dir = \"./input/train/\"\n",
    "tr1_dir = \"defog/\"\n",
    "tr1_fr  = 100\n",
    "tr2_dir = \"tdcsfog/\"\n",
    "tr2_fr  = 128\n",
    "\n",
    "# simulating the dataLoader\n",
    "all_files = readdir(base_dir*tr1_dir)\n",
    "\n",
    "rr = rand(1:length(all_files))\n",
    "@show rr\n",
    "# reading in a specific file\n",
    "df1 = CSV.read(base_dir*tr1_dir*all_files[rr] , DataFrames.DataFrame)\n",
    "df1.Time ./= tr1_fr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = CSV.read(\"./input/events.csv\", DataFrames.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii = size(df1)[1]\n",
    "sii = rand(1:nii)\n",
    "aii = sii .+ (1:min(nii-sii,500*tr1_fr))\n",
    "\n",
    "p = Plots.plot(size=(1300,400)) # layout=(3,1),\n",
    "color = 2 .* df1.StartHesitation .+ df1.Turn\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccV[aii], color=color[aii], label=false,title=\"AccV\",titlefontsize=9,msw=0,ms=1)\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccML[aii],color=color[aii], label=false,title=\"AccML\",titlefontsize=9,msw=0,ms=1)\n",
    "Plots.scatter!(p, df1.Time[aii], df1.AccAP[aii],color=color[aii], label=false,title=\"AccAP\",titlefontsize=9,msw=0,ms=1)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.savefig(\"need_to_average.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming from Freq1 to Freq2\n",
    "\n",
    "This section is about the transformation of a signal at frequency $\\omega_1$ to a signal with frequency $\\omega_2$, where frequency means the times a signal is sampled __in a second__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transform (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function transform(d1, fr1::Integer, fr2::Integer)\n",
    "    \n",
    "    nd1 = length(d1)\n",
    "    nd2 = Int(floor(nd1*fr2/fr1))\n",
    "    λ   = (0:(nd2-1))*fr1/fr2\n",
    "    ii1 = Int.(floor.(λ))\n",
    "    λ  -= ii1\n",
    "    d1  = vcat(deepcopy(d1), d1[end])\n",
    "\n",
    "    return (1 .- λ) .* d1[1 .+ ii1] + λ .* d1[2 .+ ii1]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# debug\n",
    "#t0 = collect(0:1.25:10)\n",
    "#t,λ = transform(t0,8,10)\n",
    "#@show t\n",
    "\n",
    "accV1 = df1.AccV[aii]\n",
    "time1 = df1.Time[aii]\n",
    "accV2 = transform(accV1, tr1_fr, tr2_fr)\n",
    "time2 = transform(time1, tr1_fr, tr2_fr)\n",
    "\n",
    "p = Plots.scatter(time1, accV1) # df1.AccV[aii])\n",
    "Plots.scatter!(p, time2, accV2 ,msw=0,ms=2) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot!(p,xlim=(1100,1101))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the second data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating the dataLoader\n",
    "all_f2 = readdir(base_dir*tr2_dir)\n",
    "\n",
    "rr2 = rand(1:length(all_f2))\n",
    "@show rr2\n",
    "# reading in a specific file\n",
    "df2 = CSV.read(base_dir*tr2_dir*all_f2[rr2] , DataFrames.DataFrame)\n",
    "df2.Time ./= tr2_fr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii = size(df2)[1]\n",
    "sii = rand(1:nii)\n",
    "aii = sii .+ (1:min(nii-sii,10*tr2_fr))\n",
    "\n",
    "p = Plots.plot(layout=(3,1),size=(800,400))\n",
    "color = 2 .* df2.StartHesitation .+ df2.Turn\n",
    "Plots.plot!(p[1], df2.Time[aii], df2.AccV[aii], color=color[aii], label=false,title=\"AccV\",titlefontsize=9)\n",
    "Plots.plot!(p[1], df1.Time[aii], df1.AccV[aii], label=false,title=\"AccV\",titlefontsize=9)\n",
    "\n",
    "Plots.plot!(p[2], df2.Time[aii], df2.AccML[aii],color=color[aii], label=false,title=\"AccML\",titlefontsize=9)\n",
    "Plots.plot!(p[2], df1.Time[aii], df1.AccML[aii], label=false,title=\"AccML\",titlefontsize=9)\n",
    "\n",
    "Plots.plot!(p[3], df2.Time[aii], df2.AccAP[aii],color=color[aii], label=false,title=\"AccAP\",titlefontsize=9)\n",
    "Plots.plot!(p[3], df1.Time[aii], df1.AccAP[aii], label=false,title=\"AccAP\",titlefontsize=9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your task is to:\n",
    "\n",
    "1. build a data loader that samples the __events__ (from the \"events.csv\" file), copies chunks using a number $D$ of _continuous_ samples. The output is assigned as a weights into which classes are present in the series of length $D$.\n",
    "\n",
    "1. Build a neural network that is capable to read in $D$ values and produce a $K$ outputs, where $K$ is the number of different classifications possible.\n",
    "\n",
    "1. Evaluate the system for different values of $D$ and different architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we don't need a struct, \n",
    "# ehh \n",
    "struct myDataLoader\n",
    "    sampler\n",
    "    D\n",
    "    getNextBatch\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transform (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import CSV, DataFrames, Plots\n",
    "events = CSV.read(\"./input/events.csv\", DataFrames.DataFrame)\n",
    "\n",
    "\n",
    "function transform(d1, fr1::Integer, fr2::Integer)\n",
    "    \n",
    "    nd1 = length(d1)\n",
    "    nd2 = Int(floor(nd1*fr2/fr1))\n",
    "    λ   = (0:(nd2-1))*fr1/fr2\n",
    "    ii1 = Int.(floor.(λ))\n",
    "    λ  -= ii1\n",
    "    d1  = vcat(deepcopy(d1), d1[end])\n",
    "\n",
    "    return (1 .- λ) .* d1[1 .+ ii1] + λ .* d1[2 .+ ii1]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadRecording (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loadFile(path)\n",
    "    CSV.read(path, DataFrames.DataFrame)\n",
    "end\n",
    "#load in rows in time interval [first,last]\n",
    "function loadRecording(file_name, first_index, last_index)\n",
    "    data = []\n",
    "    path_tdcs = \"./input/train/tdcsfog/\"\n",
    "    path_de = \"./input/train/defog/\"\n",
    "    path_notype = \"./input/train/notype/\"\n",
    "    frequency = 128\n",
    "    try \n",
    "        data = loadFile(path_tdcs * file_name*\".csv\")\n",
    "    catch\n",
    "        try\n",
    "            frequency = 100\n",
    "            data = loadFile(path_de * file_name*\".csv\")\n",
    "        catch \n",
    "            # it means we have notype\n",
    "            # do we want to load them in , or what ? because the structure is a bit different, there are no event type annotations.. \n",
    "            # data = loadFile(path_notype * file_name*\".csv\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    index_start = trunc(Int64,frequency *first_index ) + 2\n",
    "    index_end = min(trunc(Int64,frequency *last_index ) + 1,size(data)[1])\n",
    "\n",
    "\n",
    "    (Matrix(data[index_start:index_end,:]),frequency)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " ([1103.0 -9.39529972114623 … 1.0 0.0; 1104.0 -9.16660317480122 … 1.0 0.0; … ; 1889.0 -8.5489501493737 … 1.0 0.0; 1890.0 -8.56789013914377 … 1.0 0.0], 128)\n",
       " ([1458.0 -8.94870175413821 … 1.0 0.0; 1459.0 -9.05473787136403 … 1.0 0.0; … ; 5270.0 -8.91070800593675 … 1.0 0.0; 5271.0 -8.86710149396174 … 1.0 0.0], 128)\n",
       " ([6998.0 -10.2779361750618 … 1.0 0.0; 6999.0 -9.99570845868899 … 1.0 0.0; … ; 7523.0 -9.61131702426238 … 1.0 0.0; 7524.0 -9.17878724878662 … 1.0 0.0], 128)\n",
       " ([3597.0 -8.69936143533898 … 1.0 0.0; 3598.0 -8.77127881535382 … 1.0 0.0; … ; 3876.0 -8.60192171420836 … 1.0 0.0; 3877.0 -8.6538965989354 … 1.0 0.0], 128)\n",
       " ([3881.0 -9.16232640273608 … 1.0 0.0; 3882.0 -9.13981486072401 … 1.0 0.0; … ; 4079.0 -10.0472318960615 … 1.0 0.0; 4080.0 -10.5986136370634 … 1.0 0.0], 128)\n",
       " ([2054.0 -9.58634938862899 … 1.0 0.0; 2055.0 -9.41231919415004 … 1.0 0.0; … ; 2206.0 -9.95826843635929 … 1.0 0.0; 2207.0 -10.0628253297948 … 1.0 0.0], 128)\n",
       " ([2510.0 -10.9445153324145 … 1.0 0.0; 2511.0 -10.4187890040757 … 1.0 0.0; … ; 2636.0 -8.52627925677611 … 1.0 0.0; 2637.0 -8.83465643790808 … 1.0 0.0], 128)\n",
       " ([2111.0 -9.76780225097328 … 1.0 0.0; 2112.0 -10.0753886255984 … 1.0 0.0; … ; 2253.0 -9.19211661412227 … 1.0 0.0; 2254.0 -9.19530136839325 … 1.0 0.0], 128)\n",
       " ([4461.0 -9.21214861516373 … 1.0 0.0; 4462.0 -9.26138122551309 … 1.0 0.0; … ; 4731.0 -9.25569298690608 … 1.0 0.0; 4732.0 -9.14387047902633 … 1.0 0.0], 128)\n",
       " ([4774.0 -9.07833241991207 … 1.0 0.0; 4775.0 -9.01729057263429 … 1.0 0.0; … ; 5099.0 -9.44682313439086 … 1.0 0.0; 5100.0 -9.43902510375752 … 1.0 0.0], 128)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load D samples from events.csv \n",
    "function loadSamplesFromEvents(starting_from::Int32, num_d::Int32, event_df::DataFrames.DataFrame )\n",
    "    num_events = size(event_df)[1]\n",
    "    ending_with = min(starting_from+num_d-1,num_events) # to avoid \"index not found\" exception \n",
    "    # select events to be loaded \n",
    "    # we could also do also just load randomly , if that is desired \n",
    "    chosen_events = [event_df[row,:] for row in starting_from:ending_with]\n",
    "    train_data = []    \n",
    "    for event in chosen_events\n",
    "        series_event = loadRecording(event.Id,event.Init,event.Completion)\n",
    "        push!(train_data,series_event)\n",
    "        \n",
    "    end\n",
    "    \n",
    "    train_data\n",
    "end\n",
    "raw_data = loadSamplesFromEvents(1,10,events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Any[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_freq = [x==100 for (_,x) in raw_data]\n",
    "raw_data[low_freq]\n",
    "# I guess data should be transformed.. sometime for training ? anyway.. the first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getNextBatch (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function transform_batch(batch) \n",
    "    # not sure how to do that .. we can , or should only transform the signals.. or we we extend also the labels ?? ehh \n",
    "    batch\n",
    "end\n",
    "\n",
    "function getNextBatch(data_loader)\n",
    "    from_index = data_loader.current_index\n",
    "    chunk_size = data_loader.d\n",
    "    \n",
    "    batch = loadSamplesFromEvents(from_index,chunk_size,data_loader.events_dataframe)\n",
    "    data_loader.current_index += chunk_size\n",
    "    #maybe there is no need for reset.. mark it as to be removed ? \n",
    "    # if (data_loder.current_index > size(data_loader.events_dataframe)[1])\n",
    "    #     data_loader.current_index = 1\n",
    "    # end \n",
    "    # transform data if neccessary I guess \n",
    "    batch = tranform_batch(batch)\n",
    "\n",
    "    batch\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct data_loader \n",
    "    current_index::Int32\n",
    "    d::Int32\n",
    "    getNext\n",
    "    events_dataframe\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " ([1103.0 -9.39529972114623 … 1.0 0.0; 1104.0 -9.16660317480122 … 1.0 0.0; … ; 1889.0 -8.5489501493737 … 1.0 0.0; 1890.0 -8.56789013914377 … 1.0 0.0], 128)\n",
       " ([1458.0 -8.94870175413821 … 1.0 0.0; 1459.0 -9.05473787136403 … 1.0 0.0; … ; 5270.0 -8.91070800593675 … 1.0 0.0; 5271.0 -8.86710149396174 … 1.0 0.0], 128)\n",
       " ([6998.0 -10.2779361750618 … 1.0 0.0; 6999.0 -9.99570845868899 … 1.0 0.0; … ; 7523.0 -9.61131702426238 … 1.0 0.0; 7524.0 -9.17878724878662 … 1.0 0.0], 128)\n",
       " ([3597.0 -8.69936143533898 … 1.0 0.0; 3598.0 -8.77127881535382 … 1.0 0.0; … ; 3876.0 -8.60192171420836 … 1.0 0.0; 3877.0 -8.6538965989354 … 1.0 0.0], 128)\n",
       " ([3881.0 -9.16232640273608 … 1.0 0.0; 3882.0 -9.13981486072401 … 1.0 0.0; … ; 4079.0 -10.0472318960615 … 1.0 0.0; 4080.0 -10.5986136370634 … 1.0 0.0], 128)\n",
       " ([2054.0 -9.58634938862899 … 1.0 0.0; 2055.0 -9.41231919415004 … 1.0 0.0; … ; 2206.0 -9.95826843635929 … 1.0 0.0; 2207.0 -10.0628253297948 … 1.0 0.0], 128)\n",
       " ([2510.0 -10.9445153324145 … 1.0 0.0; 2511.0 -10.4187890040757 … 1.0 0.0; … ; 2636.0 -8.52627925677611 … 1.0 0.0; 2637.0 -8.83465643790808 … 1.0 0.0], 128)\n",
       " ([2111.0 -9.76780225097328 … 1.0 0.0; 2112.0 -10.0753886255984 … 1.0 0.0; … ; 2253.0 -9.19211661412227 … 1.0 0.0; 2254.0 -9.19530136839325 … 1.0 0.0], 128)\n",
       " ([4461.0 -9.21214861516373 … 1.0 0.0; 4462.0 -9.26138122551309 … 1.0 0.0; … ; 4731.0 -9.25569298690608 … 1.0 0.0; 4732.0 -9.14387047902633 … 1.0 0.0], 128)\n",
       " ([4774.0 -9.07833241991207 … 1.0 0.0; 4775.0 -9.01729057263429 … 1.0 0.0; … ; 5099.0 -9.44682313439086 … 1.0 0.0; 5100.0 -9.43902510375752 … 1.0 0.0], 128)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create train data \n",
    "\n",
    "dataLoader = data_loader(1,10,getNextBatch,events)\n",
    "dataLoader.getNext(dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " ([2547.0 -8.49477605840235 … 1.0 0.0; 2548.0 -8.43373488137218 … 1.0 0.0; … ; 3640.0 -9.58295280537681 … 1.0 0.0; 3641.0 -9.6381606280407 … 1.0 0.0], 128)\n",
       " ([4336.0 -8.7572528813337 … 1.0 0.0; 4337.0 -8.57360442796522 … 1.0 0.0; … ; 4447.0 -8.73567091118528 … 1.0 0.0; 4448.0 -8.71308341254031 … 1.0 0.0], 128)\n",
       " ([976.0 -10.2697023739648 … 0.0 1.0; 977.0 -10.4221368734523 … 0.0 1.0; … ; 1168.0 -10.5300521560983 … 0.0 1.0; 1169.0 -10.0656873105244 … 0.0 1.0], 128)\n",
       " ([2535.0 -11.3551795848546 … 1.0 0.0; 2536.0 -11.6133956666172 … 1.0 0.0; … ; 2633.0 -11.0483585524381 … 1.0 0.0; 2634.0 -10.8600249441118 … 1.0 0.0], 128)\n",
       " ([3951.0 -9.29739441084866 … 1.0 0.0; 3952.0 -9.4475271054468 … 1.0 0.0; … ; 4481.0 -9.40982942699934 … 1.0 0.0; 4482.0 -9.34489392319113 … 1.0 0.0], 128)\n",
       " ([1348.0 -9.9681840034427 … 1.0 0.0; 1349.0 -10.4202789376938 … 1.0 0.0; … ; 1469.0 -10.1278391602663 … 1.0 0.0; 1470.0 -10.5649362782316 … 1.0 0.0], 128)\n",
       " ([2096.0 -8.42144112275253 … 1.0 0.0; 2097.0 -8.57703835896847 … 1.0 0.0; … ; 2273.0 -9.87235283577528 … 1.0 0.0; 2274.0 -9.78207938341774 … 1.0 0.0], 128)\n",
       " ([1493.0 -10.7957604088188 … 1.0 0.0; 1494.0 -10.5760847829342 … 1.0 0.0; … ; 1793.0 -9.00648802392779 … 1.0 0.0; 1794.0 -9.00289436283919 … 1.0 0.0], 128)\n",
       " ([2363.0 -10.067822408944 … 1.0 0.0; 2364.0 -10.0300461094085 … 1.0 0.0; … ; 3303.0 -10.5119843967002 … 1.0 0.0; 3304.0 -10.4787163674013 … 1.0 0.0], 128)\n",
       " ([2678.0 -8.56450277567944 … 1.0 0.0; 2679.0 -9.06182034986374 … 1.0 0.0; … ; 3124.0 -8.53915167261645 … 1.0 0.0; 3125.0 -8.49871891193792 … 1.0 0.0], 128)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataLoader.getNext(dataLoader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
